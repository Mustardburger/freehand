# Freehand ultrasound without external trackers

This repository contains a algorithms to train deep neural networks, for predicting spatial transformation between freehand ultrasound images. The model training uses scans of ultrasound image frames acquired with ground-truth frame locations from external spatial trackers, with the aim to reconstruct the spatial location or relative transformation between newly acquired scans.

The most up-to-date code is in the `dev0` branch. You can adapt the train and test scripts with your local data.

The link to the data used in paper ``Qi. et al. Trackerless freehand ultrasound with sequence modelling and auxiliary transformation over past and future frames'' will be made available here upon publication (due to local regulatory requirement).
